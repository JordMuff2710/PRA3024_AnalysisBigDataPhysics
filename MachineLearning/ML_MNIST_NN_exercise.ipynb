{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "XpGNAvNbSzkK",
    "outputId": "9a919235-051c-4ab3-ec61-74809cd20901"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IRtFU1ZWO0a"
   },
   "outputs": [],
   "source": [
    "# load training and test images (x), and their respective classified labels (y).\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "5G5KLASFWlnX",
    "outputId": "d2dde084-fb17-4046-903b-699bf115e5f7"
   },
   "outputs": [],
   "source": [
    "# Investigate the data\n",
    "\n",
    "print(\"Training data shape: \", x_train.shape) # (60000, 28, 28) -- 60000 images, each 28x28 pixels\n",
    "print(\"Test data shape\", x_test.shape) # (10000, 28, 28) -- 10000 images, each 28x28\n",
    "print(\"First 10 training labels as digits:\\n\", y_train[:10])\n",
    "print(\"\")\n",
    "\n",
    "# Plot the first 10 images\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Find a way to plot a sample of 10 images of hand-written digits in the training data\n",
    "### END STUDENT CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "nk6I1PweS7Br",
    "outputId": "d7ceddcb-9bf7-4a46-f0db-9a9341be893d"
   },
   "outputs": [],
   "source": [
    "# Pre-processing of data\n",
    "\n",
    "# Flatten the images\n",
    "image_vector_size = 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_vector_size)\n",
    "print(\"reshaped training data format: \", x_train.shape) # -- 60000 images, now flat arrays of 28*28 long\n",
    "\n",
    "# one-hot encode the labels\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"First 10 training lables as one-hot encoded vectors:\\n\", y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "f8HyorlxTUgO",
    "outputId": "66c19d84-eca3-4a5d-967e-be659ace7c5b"
   },
   "outputs": [],
   "source": [
    "# Build the network\n",
    "from keras.layers import Dense # Dense layers are \"fully connected\" layers\n",
    "from keras.models import Sequential # Documentation: https://keras.io/models/sequential/\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input layer requires the special input_shape parameter, which should equal the shape of our training data.\n",
    "# The output layer must be the same size as the (one-hot encoded) labels.\n",
    "# Choose a non-linear activation function such as a sigmoid, or relu.\n",
    "# For classification purposes, where the outputs are normalized 'probabilities' between the classes,\n",
    "#  one typically uses the softmax activation function for the last layer.\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> add Dense (fully connected) layers to the model to connect input to output.\n",
    "###  Make sure that the dimensionality is correct: input should be # pixels large, \n",
    "###  output should be #classes large. Google is your friend.\n",
    "### END STUDENT CODE ###\n",
    "\n",
    "# Print model summary. Shows network layout, and # free parameters (weights + biases) to adapt while learning.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "xLA4UyhnTjUK",
    "outputId": "26d29ed9-5a73-4d39-b616-c80a6b980a46"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "# A good loss function for probability classification that works well with softmax is the 'categorical crossentropy'.\n",
    "#  It's a function of the difference between the predicted y (from running the image through the network),\n",
    "#  and the actual label y that we get from the dataset. The larger the loss, the worst our network is performing.\n",
    "# A good optimizer is the stochastic gradient descent (sgd) or adam.\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Call model.compile with the right arguments.\n",
    "### END STUDENT CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "Hpxjqt02r4bJ",
    "outputId": "3021301b-eb8a-400f-b3ee-988c948bb2a6"
   },
   "outputs": [],
   "source": [
    "# Let's see how good the model 'predicts' some hand-written digits in our test dataset, without training.\n",
    "# It's probably random: so for 10 digits, it should get an accuracy around 0.1 .\n",
    "\n",
    "loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> call model.predict_proba() on the test images, and show the predictions of the\n",
    "###  untrained model for the first 10 images. Also, plot those images, as you did above.\n",
    "### END STUDENT CODE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "gCkCK2BZZRG5",
    "outputId": "30dff18c-e67e-4d2f-ad89-453960eca494"
   },
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "\n",
    "# BATCH_SIZE defines how many images to process at once.\n",
    "# EPOCHS defines how often to run over the total data (60000 images)\n",
    "# (Note that a small part of the train data is internally split off for independent validation of the metrics)\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Edit the parameters below to obtain a better accuracy in the training.\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "arNvXRj8W3i9",
    "outputId": "f28f2cfd-eada-498c-b2ec-55eb5ec3cc03"
   },
   "outputs": [],
   "source": [
    "# Plot the progression of the training process\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "AY46AfbHT0SZ",
    "outputId": "88a7f96b-12d6-4552-a95a-3e7079550aed"
   },
   "outputs": [],
   "source": [
    "# Evaluate model on test data - how often does the network predict the right label after training?\n",
    "\n",
    "loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
    "\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')\n",
    "\n",
    "# Make a confusion matrix to see which numbers are difficult to disentangle\n",
    "\n",
    "y_pred_test = model.predict_proba(x_test) # obtain one-hot encoded predictions for the x_test images\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Now predict again the labels for the test images, but after proper training.\n",
    "###  Build a confusion matrix to show which labels we often confuse with what.\n",
    "###  (Note that the y_test and y_pred are still one-hot encoded, so you need to get\n",
    "###   the index of the maximum entry to find the corresponding predicted 'number'.\n",
    "### END STUDENT CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "e824_G2qZ4Lg",
    "outputId": "f505fd0e-eb62-4f34-ba7e-d709f5f3dfd8"
   },
   "outputs": [],
   "source": [
    "# Show some predicted labels and their probabilities to be correct\n",
    "\n",
    "### STUDENT CODE HERE ###\n",
    "### --> Now show some hand-written digit images from the test sample, \n",
    "###  their corresponding true label, their predicted label from your network,\n",
    "###  and the probability associated with that prediction.\n",
    "### END STUDENT CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3GO3lDpR4qm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_MNIST_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
